---
title: "Tidymodels introduction - EcoDataScience"
author: "Gavin McDonald - Environmental Markets Solutions Lab (emLab)"
date: "11/19/2019"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(here)
```

## Session overview

This is *not* a comprehensive overview of predictive modeling (*a.k.a.* supervised machine learning)

For that, see Max Kuhn's fantastic [Applied Predictive Modeling](http://appliedpredictivemodeling.com) (he'll also be teaching a short course at next year's [rstudio::conf](https://rstudio.com/conference/))

I'd also recommend [An introduction to statistical learning](http://faculty.marshall.usc.edu/gareth-james/ISL/) by Gareth, James, Hastie and Tibshirani

This *is* a very high-level overview of the predictive modeling process and what's possible using the new `tidymodels` universe of R packages

## Data science workflow

```{r, out.width = "900px"}
knitr::include_graphics(here::here("images/data_science_workflow.png"))
```

Image credit: [Edgar Ruiz](https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/) (adapted from Wickham and Grolemund's [R for Data Science](https://r4ds.had.co.nz/explore-intro.html) book).

## Tidymodels workflow

```{r, out.width = "900px"}
knitr::include_graphics(here::here("images/tidymodels_workflow.png"))
```

Image credit: [Edgar Ruiz](https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/)

## Tidymodels packages

`tidymodels` packages include (among others):   

* `rsample` - data sampling    
* `recipes` - data pre-processing  
* `parsnip` - unified modeling interface  
* `yardstick` - measuring model performance  
* `dials` and `tune` - hyperparameter tuning
* `probably` - post-processing class probabilities 

Loading `tidymodels` also loads some `tidyverse` packages:  

* `dplyr`
* `ggplot2` 
* `purrr`

## Types of supervised machine learning

* **Regression** tries to predict numeric (continuous) variable (*e.g.*, what price do we expect this house to have?)  
* **Classification** tries to predict categorical (discrete) variable (*e.g.*, do we expect this person to have a good or bad credit score?)  

## Data sampling using `rsample`

Challenge is to "spend" our data to find the optimal model. Data can be spent in two ways:

1. **Training dataset** is used to estimate model parameters
2. **Testing dataset** is used to estimate model predictive performance

## Data sampling using `rsample`

* Basic function for splitting data is `rsample::initial_split`  

-- *e.g.*, `housing_split <- initial_split(mtcars, prop = 0.75)`  

* `rsample::training` and `rsample::testing` then used to extract data  

-- e.g., `housing_training <- training(housing_split)` and `testing_data <- testing(housing_split)`  

* Can define proportion of data to be used for model training (`prop`), and variable used for stratified sampling (`strata`)  
* `rsample` also has functions for creating bootstrap samples (`bootstraps`) and cross-validation samples (*e.g*, `vfold_cv`)

## Data pre-processing using `recipes`  

Once we have training and testing data, may need to do some data pre-processing before we can fit models. Examples include:  

* Data transformations, such as centering and scaling to put variables in same units  
* Removing correlated variables  
* Encoding or creating dummy variables  
* Imputing missing data  

Importantly, these steps require data - but we don't want to use information from the testing dataset (that would be "data leakage")  

Therefore, we specify design matrices or blueprints (`recipes`) that specify the desired steps, rather than pre-processing data directly    

Data pre-processing (also known as feature engineering) is a whole field in itself. See the new book by [Kuhn and Johson](http://www.feat.engineering)

## Data pre-processing using `recipes`  

* Basic function for initiating recipe is `recipes::recipe`  

-- *e.g.*, `housing_recipe <- recipe(price ~. data = housing_training)`

* We can then add steps to the recipe using pipes

-- *e.g.*, `step_corr()`, `step_center()`, `step_scale()`, ` step_dummy()`, `step_meanimpute()`

* For each step, can specify whether we what type of variables we want step to act on  

-- *e.g*, `all_numeric()`, `all_outcomes()`, `all_predictors()`, or `dplyr` verbs like `starts_with`, `contains`, etc.  

## Data pre-processing using `recipes`  

An example:

```{r echo = TRUE,eval=FALSE}
housing_recipe <- housing_training %>%
  # Specify regression model formula
  recipe(price ~.)  %>%
  # step_corr removes highly correlated variables
  step_corr(all_numeric(), -all_outcomes()) %>%
  # step_center normalizes data to have a mean of 0
  step_center(all_numeric(), -all_outcomes()) %>%
  # step_scale normalizes data to have a standard deviation of 0
  step_scale(all_numeric(), -all_outcomes()) %>%
  # Create dummy variable columns for all factor columns
  step_dummy(all_predictors(),-all_numeric())
```


## Data pre-processing using `recipes`  

Once we've defined the recipe, we're ready to apply it  

* We estimate the parameters for the recipe using `prep` (*e.g.*, `housing_recipe_prepped <- prep(housing_recipe, training = housing_training`))  

* We apply the prepped recipe to the training data using `juice` (*e.g.*, `housing_training_juiced <- juice(housing_recipe_prepped)`)  

* We apply the prepped recipe to the testing data using `bake` (*e.g.*, `housing_testing_baked <- bake(housing_testing)`)  

## Model training using `parsnip`  

With pre-processed data, we're now ready to train our model!  

The old way of doing things...

```{r, echo = TRUE, eval = FALSE}
# From randomForest
rf_1 <- randomForest(x, y, mtry = 12, ntree = 2000, importance = TRUE)

# From ranger
rf_2 <- ranger(
  y ~ ., 
  data = dat, 
  mtry = 12, 
  num.trees = 2000
)

# From sparklyr
rf_3 <- ml_random_forest(
  dat, 
  intercept = FALSE, 
  response = "y", 
  features = names(dat)[names(dat) != "y"], 
  col.sample.rate = 12,
  num.trees = 2000
)
```

## Model training using `parsnip`  

The new way of doing things...

```{r, echo = TRUE, eval = FALSE}
# From randomForest
rf_1 <- rand_forest(mtry = 12, trees = 2000) %>%
  set_engine("randomForest") %>%
  fit(y ~ ., data = dat)

# From ranger
rf_2 <- rand_forest(mtry = 12, trees = 2000) %>%
  set_engine("ranger") %>%
  fit(y ~ ., data = dat)

# From sparklyr
rf_3 <- rand_forest(mtry = 12, trees = 2000) %>%
  set_engine("spark") %>%
  fit(y ~ ., data = dat)
```


## Model training using `parsnip`  

`parsnip` provides a standardized interface for building many types of models from many different packages. Allows you to specify:

* The **type** of model (*e.g.*, linear regression, random forest, support vector machine, neural network)  
* The **mode** of prediction (classification or regression)
* The specific computational **engine** or package to use under the hood (*e.g.*, `ranger`, `randomForest`, `kernlab`)

You can then use `fit` to fit the model, and `predict` to make predictions with the model

## Model training using `parsnip`  

Some examples:

```{r, echo = TRUE, eval = FALSE}
# Define the models
housing_fit_lm <- linear_reg() %>%
  set_engine("lm") 

housing_model_randomForest <-  rand_forest(trees = 100, mode = "regression") %>%
  set_engine("randomForest") 

# Fit the models
housing_fit_lm <- housing_model_lm %>%
  fit(price ~ ., data = housing_training_juiced)

housing_fit_randomForest <- housing_model_randomForest %>%
  fit(price ~ ., data = housing_training_juiced)

# Make predictions

housing_lm_predict <- housing_fit_lm %>%
  predict(housing_testing_baked)

housing_randomForest_predict <- housing_fit_randomForest %>%
  predict(housing_testing_baked)
```

## Testing model performance using `yardstick`  

Once we have models trained, we can test how well they work  

* `metrics` function generates a default metric set using dataframe of `truth` and `estimate` columns  

-- For regression, these are root mean squared error, r-squared, and mean absolute error  

-- For regression, these are accuracy and Kappa (compares observed accuracy to random chance)  

* Can define custom sets of metrics using `metric_set`  

* Can use individual functions for all metric types (*e.g.*, `rsq`, `accuracy`, `roc_auc`, `precision`, etc)  

* Can generate ROC and precision recall curves using `roc_curve`, `pr_curve`  

## On the horizon for `tidymodels`

* [tune](https://tidymodels.github.io/tune/) package for more streamlined hyperparameter tuning 
* [workflows](https://github.com/tidymodels/workflows) package for putting it all together (pre-processing, modeling, and post-processing) 

## Live session

Adapted from Edgar Ruiz's [A Gentle Introduction to tidymodels](https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/)